{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n",
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 4, 'f2.txt': 4, 'f3.txt': 4}\n",
      "\n",
      "Unique words in every file\n",
      " {'This', 'book', 'My', 'pen', 'interesting', 'my', 'is'}\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Dictionary of unique words\n",
      " {'This': 0, 'book': 1, 'My': 2, 'pen': 3, 'interesting': 4, 'my': 5, 'is': 6}\n",
      "\n",
      "Dictionary of files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n",
      "[[1. 1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 0. 1. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Write something for searching:  pen\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Resultant Vector is: \n",
      " [[0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "Max value is: \n",
      " [1.]\n",
      "\n",
      "Index of Max value is: \n",
      " 1\n",
      "File with maximum value: f2.txt\n",
      "\n",
      "This is my pen\n"
     ]
    }
   ],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n",
    "root_directory = 'E:\\Semester 06\\Machine Learning_ML\\IRS_Assignment no 02\\BCSF20M503_IRS_Solution\\Data_file' #telling the path of the directory where data files are contained\n",
    "\n",
    "for subdir, dirs, files in os.walk(root_directory): #os.walk() is used to traverse all the directories including root directory\n",
    "    for file in files:\n",
    "        file_count+=1   #counting all the files \n",
    "        file_path = os.path.join(subdir, file) #os.path.join() is used to generate full path to the file\n",
    "        fname = open(file_path, 'r') #open is used to open the file using its path in r means reading mode\n",
    "        word = fname.read() #read() reads the file and stores the result as a string\n",
    "        temp = word.split() #splits the words on whitespaces and stores in temporary variable temp\n",
    "        files_dict[file] = len(temp) #counts the splitted words, and stores in files_dict\n",
    "        unique_word_set.update(temp) #update fuction updates the values in a set. Here when splitting the words adding them side by side in a set\n",
    "        \n",
    "print(\"\\nTotal Number  of files\\n\", file_count)\n",
    "print(\"\\nDictionary containing  files\\n\", files_dict)\n",
    "print(\"\\nUnique words in every file\\n\", unique_word_set)\n",
    "\n",
    "row_file = file_count # no of rows equal to total no of files\n",
    "col_word = len(unique_word_set) #no of cols equal to total unique words\n",
    "term_doc_matrix = np.zeros((row_file,col_word)) #initializing term_doc_matrix with zero\n",
    "print(term_doc_matrix)\n",
    "\n",
    "dict_for_unique_words = {} # in this dict, each word is a key, and corresponding index is the value\n",
    "dict_for_unique_words =  {word: index for index, word in enumerate(unique_word_set)} #the enumerate() function is used to iterate over the words in the set, along with their corresponding index starting from 0\n",
    "print(\"\\nDictionary of unique words\\n\", dict_for_unique_words)\n",
    "\n",
    "dict_for_files = {}\n",
    "dict_for_files =  {file: index for index, file in enumerate(files)} #the enumerate() function is used to iterate over the words in the set, along with their corresponding index starting from 0\n",
    "print(\"\\nDictionary of files\\n\", dict_for_files)\n",
    "\n",
    "for i, file in enumerate(files): #Loop through each file\n",
    "    f = open(file, 'r')\n",
    "    file_contents = f.read()  #Reading the file contents\n",
    "    words = file_contents.split() #Split the file contents into words\n",
    "    for word in words: #Loop through each word in the file\n",
    "        if word in dict_for_unique_words: #Check if the word is in the set of unique words\n",
    "            word_index = dict_for_unique_words[word] #Get the index of the word\n",
    "            term_doc_matrix[i][word_index] = 1 #Set the corresponding value in the matrix to 1\n",
    "print(term_doc_matrix)\n",
    "\n",
    "col_vector = np.zeros((len(unique_word_set),1))   #initializing column_vector with zero\n",
    "print(col_vector)\n",
    "\n",
    "query = input(\"\\nWrite something for searching:  \")  #Asking for user input\n",
    "for word in query.split(): #Split query into words and check if each word is in unique_words\n",
    "    if word in dict_for_unique_words: #If the word is in unique_words, increment the corresponding count in column_vector\n",
    "        col_vector[dict_for_unique_words[word]] += 1 \n",
    "    else:\n",
    "        print('Such query is not found in the data files')\n",
    "        sys.exit()\n",
    "print(col_vector)\n",
    "\n",
    "resultant_vector = np.dot(term_doc_matrix,col_vector) #res_vector is obtained by taking dot product of term_doc_matrix and col_vector\n",
    "print('\\nResultant Vector is: \\n', resultant_vector)\n",
    "max_value = max(resultant_vector)   #finding max_value in res_vector\n",
    "print('\\nMax value is: \\n', max_value)\n",
    "max_index = np.argmax(resultant_vector) #finding index of that max_value using argmax\n",
    "print('\\nIndex of Max value is: \\n', max_index)\n",
    "\n",
    "max_file_name = files[max_index]  #finding the file having max value in resultant vector\n",
    "f = open(max_file_name, 'r')\n",
    "file_contents = f.read()  #reading that file contents\n",
    "print(f\"File with maximum value: {max_file_name}\\n\")\n",
    "print(file_contents)  #printing that contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
